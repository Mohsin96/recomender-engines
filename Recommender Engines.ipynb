{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Recomendation Systems \n",
    "\n",
    "**Developer: Mayana Mohsin Khan**\n",
    "\n",
    "- **Packages used:**\n",
    "- pandas\n",
    "- numpy\n",
    "- implicit\n",
    "- surprise\n",
    "- torch\n",
    "- sklearn\n",
    "- tqdm\n",
    "- scipy\n",
    "\n",
    "### In this notebook, We compare the following approaches for building a user-item relation Recomender System using following approaches\n",
    "- surprise\n",
    "- neural network\n",
    "- implicit\n",
    "\n",
    "#### Before we begin, lets start with some theory on collaborative filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Collaborative Filtering? \n",
    "In collaborative filtering, the recommender matches the users with similar interests and predicts a recommendation based on this matching approach.\n",
    "For Example; lets consider two users, user 1 and user 2. user 1 has rated item 300 as 1 and item 24 as 0 and item 98 as 1. Now lets assume that user 2 has rated item 300 as 1. Based on the calculating the similarity between the two users, the recommender does not in this case recommend item 24 to user 2 since user 1 did not interact with it. This is an example of user-item recommender system based on user similarity. We can also use collaborative filter on item-user interactions in recommendation system using item-item similarity.\n",
    "\n",
    "**User based filtering**: In user-based filtering as we saw as an example earlier, the two users interact with the item 300 and so they have a similarity of 1. While a third user who rated item 24 shows no similarity to user 1.\n",
    "\n",
    "|user_id / item_id| 300 | 24 | 98 | similarity |\n",
    "| --- | --- | --- | --- |  --- |\n",
    "| 1 | 1 |    | 1 |   |\n",
    "| 2 | 1 |    | 1 | 1 | \n",
    "| 3 |    |  1  |    | NA  \n",
    "\n",
    "**Item based filtering**: In item-based filtering, the recommender checks for similar use have interacted with the user and recommends the articles to those user\n",
    "\n",
    "|user_id / item_id| 300 | 24 | 98 | \n",
    "| --- | --- | --- | --- |\n",
    "| 1 | 1 |    | 1 | \n",
    "| 2 | 1 |    |  |  \n",
    "| 3 |    |  1  |    |\n",
    "| <b>similarity<b> | 1 | NA  |   |\n",
    "\n",
    "\n",
    "The similarity is calculated using `pearson` or `cosine` similarity based on the programming choice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np # Manuplating the data\n",
    "import pandas as pd # Manuplating the data\n",
    "import implicit # usine als model\n",
    "from sklearn.preprocessing import MinMaxScaler # scalar to normalize the value\n",
    "from sklearn import metrics # to obtain accuracy\n",
    "import scipy.sparse as sparse # create sparse matrix\n",
    "from tqdm import tqdm # to prettify the wait time and reduce anxiety :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using suprise model for SVD, SVD++ and NMF models\n",
    "from surprise import Reader, Dataset # get the reader and dataset builder\n",
    "from surprise import SVD, NMF, SVDpp\n",
    "from surprise.model_selection import cross_validate, train_test_split # Preform cross validation and train and test split \n",
    "from surprise.model_selection import GridSearchCV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_data.csv\") # Loading training data\n",
    "test_df = pd.read_csv(\"test_data.csv\") # Loading testing Data\n",
    "valid_df = pd.read_csv(\"validation_data.csv\") # Loading Validation Data\n",
    "user_fea_df = pd.read_csv(\"user_fea.csv\") # Loading user features data\n",
    "item_fea_df = pd.read_csv(\"item_fea.csv\") # Loading item Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomender system with Surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building th Recomender systems using Suprise algorithm \n",
    "\n",
    "Comparing the RMSE, MAE values of different models to select the best model to preform the recomendation on.\n",
    "\n",
    "## Building Classifiers\n",
    "\n",
    "Using Training data to build classifier models.\n",
    "\n",
    "**Models used:**\n",
    "- SVD\n",
    "- SVD++\n",
    "- NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a suprise reader object\n",
    "reader = Reader(rating_scale=(0,1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading training data into surprise dataset with surprise reader\n",
    "data = Dataset.load_from_df(train_df[['user_id', 'item_id', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD\n",
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.0676  0.0678  0.0691  0.0672  0.0675  0.0678  0.0007  \n",
      "MAE (testset)     0.0380  0.0386  0.0392  0.0381  0.0377  0.0383  0.0005  \n",
      "Fit time          3.88    5.10    4.63    4.18    3.37    4.23    0.60    \n",
      "Test time         0.15    0.11    0.17    0.19    0.13    0.15    0.03    \n",
      "--------------------------------------------------------------------------------\n",
      "SVD++\n",
      "Evaluating RMSE, MAE of algorithm SVDpp on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.0339  0.0332  0.0339  0.0336  0.0343  0.0338  0.0004  \n",
      "MAE (testset)     0.0190  0.0186  0.0188  0.0187  0.0191  0.0188  0.0002  \n",
      "Fit time          28.00   16.99   17.63   21.38   30.50   22.90   5.45    \n",
      "Test time         0.61    0.40    0.35    0.39    0.74    0.50    0.15    \n",
      "--------------------------------------------------------------------------------\n",
      "NMF\n",
      "Evaluating RMSE, MAE of algorithm NMF on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.0644  0.0642  0.0645  0.0644  0.0644  0.0644  0.0001  \n",
      "MAE (testset)     0.0642  0.0639  0.0642  0.0641  0.0641  0.0641  0.0001  \n",
      "Fit time          6.40    5.08    6.56    6.45    5.37    5.97    0.62    \n",
      "Test time         0.14    0.08    0.10    0.11    0.15    0.12    0.03    \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# List to store models\n",
    "models = {'SVD':SVD(), \n",
    "          'SVD++':SVDpp(),\n",
    "          'NMF':NMF()}\n",
    "\n",
    "# Create and Evaluate the models\n",
    "for model_name, model in models.items():\n",
    "    print(model_name) # print model name\n",
    "    algo = model # create the model\n",
    "    cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True) # preform 10-fold cv to get measueres\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparing RMSE and MAE:**\n",
    "- SVD++ has the Least RMSE.\n",
    "- SVD++ has the least MAE.\n",
    "\n",
    "Choosing the model that has the least RMSE to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model\n",
    "\n",
    "The  Sbuilding a recomendation system with SVD++ Algorithm takes in default parameters, it is needed to obtain the most optimal parameters for the classification task.\n",
    "\n",
    "Hyperparameter tuning the SVD++ model using GridSearchCV to obtain the best parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVDpp at 0x2c55a93c550>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = SVDpp() # Create the SVD++ model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = data.build_full_trainset() # Train the model by building full training dataset\n",
    "algo.fit(training) # Fitting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict using test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           (0, 2158, 1, 1, {'was_impossible': False})\n",
       "1           (0, 2113, 1, 1, {'was_impossible': False})\n",
       "2    (0, 2070, 1, 0.9840006061147656, {'was_impossi...\n",
       "3    (0, 2026, 1, 0.923516912994206, {'was_impossib...\n",
       "4           (0, 1948, 1, 1, {'was_impossible': False})\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction on testing data\n",
    "test_pred_df = test_df.apply(lambda x: algo.predict(uid=x.user_id,iid = x.item_id,r_ui=1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2158</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2113</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2070</td>\n",
       "      <td>0.984001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2026</td>\n",
       "      <td>0.923517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1948</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id    rating\n",
       "0        0     2158  1.000000\n",
       "1        0     2113  1.000000\n",
       "2        0     2070  0.984001\n",
       "3        0     2026  0.923517\n",
       "4        0     1948  1.000000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe to return predictied rating in testing dataset\n",
    "predicted_df = pd.DataFrame({'user_id':test_pred_df.apply(lambda tup: tup[0]), # Extraing users\n",
    "                             'item_id':test_pred_df.apply(lambda tup: tup[1]), # Extraing items\n",
    "                             'rating':test_pred_df.apply(lambda tup: tup[3])}) # Extraing rating\n",
    "predicted_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extracting the top 10 items for every users using groupby user_id, \n",
    "- Sorting values in descending order.\n",
    "- Extracting the top 10 items for every users based on the predicited rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2158</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>1740</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0</td>\n",
       "      <td>558</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0</td>\n",
       "      <td>569</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "      <td>893</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>950</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0</td>\n",
       "      <td>1025</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>1455</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0</td>\n",
       "      <td>1072</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>1407</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">1</th>\n",
       "      <th>126</th>\n",
       "      <td>1</td>\n",
       "      <td>1604</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1</td>\n",
       "      <td>763</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1</td>\n",
       "      <td>578</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1</td>\n",
       "      <td>1559</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>1</td>\n",
       "      <td>1523</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1</td>\n",
       "      <td>1497</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1</td>\n",
       "      <td>699</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1</td>\n",
       "      <td>1451</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1</td>\n",
       "      <td>1450</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1</td>\n",
       "      <td>755</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id  item_id  rating\n",
       "user_id                              \n",
       "0       0          0     2158     1.0\n",
       "        18         0     1740     1.0\n",
       "        76         0      558     1.0\n",
       "        75         0      569     1.0\n",
       "        67         0      893     1.0\n",
       "        63         0      950     1.0\n",
       "        59         0     1025     1.0\n",
       "        31         0     1455     1.0\n",
       "        55         0     1072     1.0\n",
       "        35         0     1407     1.0\n",
       "1       126        1     1604     1.0\n",
       "        167        1      763     1.0\n",
       "        177        1      578     1.0\n",
       "        128        1     1559     1.0\n",
       "        129        1     1523     1.0\n",
       "        131        1     1497     1.0\n",
       "        170        1      699     1.0\n",
       "        134        1     1451     1.0\n",
       "        135        1     1450     1.0\n",
       "        168        1      755     1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Groupby \n",
    "grouped_df = predicted_df.groupby(['user_id']).apply(lambda x: x.sort_values('rating', ascending=False).nlargest(10,'rating'))\n",
    "grouped_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df[['user_id','item_id']].to_csv('test_SVDpp.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On submittion to kaggle the following model gives a very low score on NDGC evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomender System with Neural Networks\n",
    "\n",
    "- Using Pytorch to build the recomender system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Pytorch\n",
    "import torch # import torch\n",
    "import torch.nn as nn # import neural network from pytorch\n",
    "import torch.nn.functional as F # import the F score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Axulliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to preform modelling training\n",
    "def train_epocs(model, epochs=10, lr=0.01, wd=0.0, unsqueeze=False):\n",
    "    # Using adams Optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    # create the model \n",
    "    model.train()\n",
    "    # for epochs\n",
    "    for i in range(epochs):\n",
    "        users = torch.LongTensor(train_df.user_id.values) # .cuda() # convert users to tensors\n",
    "        items = torch.LongTensor(train_df.item_id.values) #.cuda() # convert items to tensors\n",
    "        ratings = torch.FloatTensor(train_df.rating.values) #.cuda() # Convert rating to tensors\n",
    "        # if the rains are unsequenced\n",
    "        if unsqueeze:\n",
    "            ratings = ratings.unsqueeze(1)\n",
    "        y_hat = model(users, items) # predict the train rating\n",
    "        loss = F.mse_loss(y_hat, ratings) # calculate the mse loss\n",
    "        optimizer.zero_grad() # apply the optimizer\n",
    "        loss.backward() # Preform backward propogation\n",
    "        optimizer.step() # preform setwise optimizer\n",
    "        print(loss.item()) # print the losss\n",
    "    test_loss(model, unsqueeze) # call the test_loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preform testing on validation set\n",
    "def test_loss(model, unsqueeze=False):\n",
    "    model.eval()\n",
    "    users = torch.LongTensor(valid_df.user_id.values) #.cuda() # convert users to tensors\n",
    "    items = torch.LongTensor(valid_df.item_id.values) #.cuda() # convert items to tensors\n",
    "    ratings = torch.FloatTensor(valid_df.rating.values) #.cuda() # convert rating to tensors\n",
    "    # if the rains are unsequenced\n",
    "    if unsqueeze:\n",
    "        ratings = ratings.unsqueeze(1)\n",
    "    y_hat = model(users, items) # predict the train rating\n",
    "    loss = F.mse_loss(y_hat, ratings) # calculate the mse loss\n",
    "    print(\"test loss %.3f \" % loss.item()) # print the test loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the neural network with matrix factorization and bias.\n",
    "\n",
    "**Neural Network Structure:**\n",
    "- Embending Layer with input dimension = num_users and 100 embending size for users\n",
    "- Embending Layer with bias for user\n",
    "- Embending layer with input dimension = num_users and 100 embending size for items\n",
    "- Embending layer with bias for items\n",
    "\n",
    "**Forward propogation:**\n",
    "Use the user and item embendings to create the network forward Propgation:\n",
    "- U = user embending\n",
    "- V = item embending\n",
    "                                            Sum of (U*V) +  b_u  + b_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Matrix factorization with bias\n",
    "class MF_bias(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size=100):\n",
    "        super(MF_bias, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_size) # user embending layers\n",
    "        self.user_bias = nn.Embedding(num_users, 1) # user embending layers with bias\n",
    "        self.item_emb = nn.Embedding(num_items, emb_size) # item embending layers\n",
    "        self.item_bias = nn.Embedding(num_items, 1) # item embending layers with bias\n",
    "        self.user_emb.weight.data.uniform_(0,0.05)\n",
    "        self.item_emb.weight.data.uniform_(0,0.05)\n",
    "        self.user_bias.weight.data.uniform_(-0.01,0.01)\n",
    "        self.item_bias.weight.data.uniform_(-0.01,0.01)\n",
    "    \n",
    "    # Calculate the forward propogation\n",
    "    def forward(self, u, v):\n",
    "        U = self.user_emb(u) \n",
    "        V = self.item_emb(v)\n",
    "        b_u = self.user_bias(u).squeeze()\n",
    "        b_v = self.item_bias(v).squeeze()\n",
    "        return (U*V).sum(1) +  b_u  + b_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of users and items\n",
    "num_users = len(train_df.user_id.unique()) # number of users \n",
    "num_items = len(train_df.item_id.unique()) # number of items\n",
    "print(num_users, num_items) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model\n",
    "Set the embending dimensions size to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MF_bias(num_users, num_items, emb_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_epocs(model, epochs=10, lr=0.1)\n",
    "train_epocs(model, epochs=25, lr=0.001, wd=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict on testing on testing set\n",
    "def predictions(test_df):\n",
    "    users = torch.LongTensor(test_df.user_id.values) # convert users to tensors\n",
    "    items = torch.LongTensor(test_df.item_id.values)  # convert items to tensors\n",
    "    rating = model(users, items) # Obatins rating by calling in the model\n",
    "    users = users.tolist()\n",
    "    items = items.tolist()\n",
    "    rating = rating.tolist()\n",
    "    # Create the dataframe\n",
    "    df = pd.DataFrame({'user_id':users, # users\n",
    "                       'item_id':items, # items\n",
    "                       'rating':rating # ratings\n",
    "                      })\n",
    "    return df # return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preform prediction\n",
    "predicted_df = predictions(test_df) \n",
    "predicted_df.head(20) # return 20 predicitons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extracting the top 10 items for every users using groupby user_id, \n",
    "- Sorting values in descending order.\n",
    "- Extracting the top 10 items for every users based on the predicited rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouby\n",
    "grouped_df = predicted_df.groupby(['user_id']).apply(lambda x: x.sort_values('rating', ascending=False).nlargest(10,'rating'))\n",
    "grouped_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the top 10 items for each users\n",
    "grouped_df[['user_id','item_id']].to_csv('test_MF_Bias.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On submittion to kaggle the following model gives a very low score on NDGC evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomender System with ALS \n",
    "\n",
    "- Using ALS model from Implicit to build the recomender system\n",
    "\n",
    "Steps:\n",
    "- Create user_item and item_user sparse matrix.\n",
    "- set alpha value.\n",
    "- create the model with best parameters.\n",
    "- recomend top 10 items for all users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Implicit library\n",
    "import implicit\n",
    "from sklearn.preprocessing import MinMaxScaler # \n",
    "from sklearn import metrics\n",
    "import scipy.sparse as sparse\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the users and items for creating a sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id item_id rating  user  item\n",
       "0       0       0      1     0     0\n",
       "1       0       1      1     0     1\n",
       "2       0       2      1     0     2\n",
       "3       0       3      1     0     3\n",
       "4       0       4      1     0     4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.user_id = train_df.user_id.astype(\"category\")\n",
    "train_df.item_id = train_df.item_id.astype(\"category\")\n",
    "train_df.rating = train_df.rating.astype(\"category\")\n",
    "train_df['user'] = train_df.user_id.cat.codes\n",
    "train_df['item'] = train_df.item_id.cat.codes\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Sparse Matrix\n",
    "\n",
    "Create the sparse matrix using `sparse.csr_matrix` from `scipy`\n",
    "- user_item\n",
    "- item_user "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to sparse matrix\n",
    "sparse_item_user = sparse.csr_matrix((train_df.rating.astype(float), (train_df.item, train_df.user))) # item_user matrixx\n",
    "sparse_user_item = sparse.csr_matrix((train_df.rating.astype(float), (train_df.user, train_df.item))) # user_item matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Set the alpha = 15 for our recomender system\n",
    "- create sparse data using item_user sparse matrix * alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 15 #The rate in which we'll increase our confidence in a preference with more interactions.\n",
    "data = (sparse_item_user * alpha).astype('double') # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building\n",
    "- ALS model using implicit package\n",
    "\n",
    "Set the following parameters:\n",
    "- alpha = 15\n",
    "- facctors = 8\n",
    "- regularization = 0.1\n",
    "- iterations = 30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f25796d1ee649139f41da277aa864c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# build the model using als algorithm from implicit package\n",
    "model = implicit.als.AlternatingLeastSquares(factors=8, regularization=0.1, iterations=30)\n",
    "model.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_vecs = model.user_factors\n",
    "item_vecs = model.item_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get user Recomendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2239/2239 [00:02<00:00, 1118.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# Function to get the recomendatins\n",
    "def recommend(person_id, sparse_person_content, person_vecs, content_vecs, num_contents):\n",
    "    # Get the interactions scores from the sparse person content matrix\n",
    "    person_interactions = sparse_person_content[person_id,:].toarray()\n",
    "    # Add 1 to everything, so that articles with no interaction yet become equal to 1\n",
    "    person_interactions = person_interactions.reshape(-1) + 1\n",
    "    # Make articles already interacted zero\n",
    "    person_interactions[person_interactions > 1] = 0\n",
    "    # Get dot product of person vector and all content vectors\n",
    "    rec_vector = person_vecs[person_id,:].dot(content_vecs.T)\n",
    "    # Scale the recomender \n",
    "    min_max = MinMaxScaler()\n",
    "    rec_vector_scaled = min_max.fit_transform(rec_vector.reshape(-1,1))[:,0]\n",
    "    # Content already interacted have their recommendation multiplied by zero\n",
    "    recommend_vector = person_interactions * rec_vector_scaled\n",
    "    # Sort the indices of the content into order of best recommendations\n",
    "    content_idx = np.argsort(recommend_vector)[::-1][:num_contents]\n",
    "    # return recomended items\n",
    "    return content_idx\n",
    "\n",
    "# create unique users list\n",
    "user_list = train_df.user_id.unique().tolist()\n",
    "# list to store recomendations\n",
    "recomendations_list = []\n",
    "# por each user in user_list get recomendations\n",
    "for user in tqdm(user_list):\n",
    "    recomendations_list.append(recommend(user, sparse_user_item, user_vecs, item_vecs,num_contents = (len(item_vecs)-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the user-item recomended dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2239/2239 [09:44<00:00,  3.83it/s]\n"
     ]
    }
   ],
   "source": [
    "item_user_recomenadations=[] # list to store items based on users\n",
    "for user in tqdm(test_df.user_id.unique().tolist()): # for earch users in testing samples\n",
    "    items_list = [] # store recomended items\n",
    "    for item in recomendations_list[user].tolist(): # for each item in recomendations we have\n",
    "        if item in test_df[test_df.user_id == user].item_id.values: # get the items values for each uuser\n",
    "            items_list.append((user,item)) # storeing the items\n",
    "            if len(items_list) > 9: # if len of items list is more then 10 then break\n",
    "                break\n",
    "    item_user_recomenadations.extend(result) # return users and items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert user - item interactions list to dataframe\n",
    "test_res = pd.DataFrame(result_item_usr,columns=['user_id','item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store to csv\n",
    "test_res.to_csv('30487420.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On submitting this csv to kaggle, this model is able to achieve the NDGC score of 0.20211."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion\n",
    "1. By Comparing the various recommender systems build above. The notebooks does a fine job in comparing the various approaches in building a successful recommender systems.\n",
    "2. The NDGC score obtained in Kaggle for ALS algorithm is the highest score achieved by the code provided in this notebook.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
